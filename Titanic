{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":3136,"databundleVersionId":26502,"sourceType":"competition"}],"dockerImageVersionId":30746,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-07-24T13:47:14.316898Z","iopub.execute_input":"2024-07-24T13:47:14.317350Z","iopub.status.idle":"2024-07-24T13:47:14.329281Z","shell.execute_reply.started":"2024-07-24T13:47:14.317314Z","shell.execute_reply":"2024-07-24T13:47:14.328031Z"},"trusted":true},"execution_count":226,"outputs":[{"name":"stdout","text":"/kaggle/input/titanic/train.csv\n/kaggle/input/titanic/test.csv\n/kaggle/input/titanic/gender_submission.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"train = pd.read_csv(\"/kaggle/input/titanic/train.csv\")\ntest = pd.read_csv(\"/kaggle/input/titanic/test.csv\")\npassId = test.PassengerId\ntest.info()","metadata":{"execution":{"iopub.status.busy":"2024-07-24T13:47:14.331133Z","iopub.execute_input":"2024-07-24T13:47:14.331565Z","iopub.status.idle":"2024-07-24T13:47:14.358264Z","shell.execute_reply.started":"2024-07-24T13:47:14.331533Z","shell.execute_reply":"2024-07-24T13:47:14.357115Z"},"trusted":true},"execution_count":227,"outputs":[{"name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 418 entries, 0 to 417\nData columns (total 11 columns):\n #   Column       Non-Null Count  Dtype  \n---  ------       --------------  -----  \n 0   PassengerId  418 non-null    int64  \n 1   Pclass       418 non-null    int64  \n 2   Name         418 non-null    object \n 3   Sex          418 non-null    object \n 4   Age          332 non-null    float64\n 5   SibSp        418 non-null    int64  \n 6   Parch        418 non-null    int64  \n 7   Ticket       418 non-null    object \n 8   Fare         417 non-null    float64\n 9   Cabin        91 non-null     object \n 10  Embarked     418 non-null    object \ndtypes: float64(2), int64(4), object(5)\nmemory usage: 36.0+ KB\n","output_type":"stream"}]},{"cell_type":"code","source":"surv = train['Survived'].value_counts()\nplt.bar(['survived','not survived'],[surv[1],surv[0]])\nplt.xlabel('status')\nplt.ylabel('count')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-07-24T13:47:14.360410Z","iopub.execute_input":"2024-07-24T13:47:14.360775Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"classNum = train['Pclass'].value_counts()\nprint(classNum)\nplt.bar(['1','2','3'],[classNum[1],classNum[2],classNum[3]])\nplt.xlabel('status')\nplt.ylabel('count')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"survived_counts = train[train['Survived'] == 1]['Pclass'].value_counts()\nnot_counts = train[train['Survived'] == 0]['Pclass'].value_counts()\n\ncategories = ['1','2','3']\ny_surv = [survived_counts[1],survived_counts[2],survived_counts[3]]\ny_not_surv = [not_counts[1],not_counts[2],not_counts[3]]\ncolor = ['red','blue','green']\n\nplt.bar(categories,y_surv,color=color)\nplt.xlabel('survived')\nplt.show()\nplt.bar(categories,y_not_surv,color=color)\nplt.xlabel('not survived')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(train.isnull().sum())\nprint('------------------------')\nprint(test.isnull().sum())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train['Age'].fillna(train['Age'].median(), inplace=True)\ntrain.drop(columns=['Cabin'], inplace=True)\n\ntest['Age'].fillna(test['Age'].median(), inplace=True)\ntest.drop(columns=['Cabin'], inplace=True)\n\n\ntrain.isnull().sum()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = train.dropna(subset='Embarked')\ntest = test.dropna(subset='Embarked')\ntrain.isnull().sum()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# train.drop(columns=['Survived'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y = train['Survived']\ntrain.drop(columns=['Survived'],inplace=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"one_hot_encoding = ['Sex','Embarked']\n\ntrain = train[['Parch','Age','Fare','Embarked','Pclass','Sex','SibSp']]\ntest = test[['Parch','Age','Fare','Embarked','Pclass','Sex','SibSp']]\n\nX = pd.get_dummies(train,columns=one_hot_encoding, dtype='int32')\nX_test = pd.get_dummies(test,columns=one_hot_encoding, dtype='int32')\n\nprint(X_test.head())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_test[X_test['Fare'].isnull()] = X_test['Fare'].median()\nprint(X_test.isnull().sum())\nprint(X_test[X_test['Fare'].isnull()])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier \n\nmodel = RandomForestClassifier(n_estimators = 100,max_depth = 5, random_state=1)\nmodel.fit(X,y)\n\npredictions = model.predict(X_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"output = pd.DataFrame({'PassengerId': passId, 'Survived': predictions})\noutput.to_csv('submission.csv', index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}